# Fine-tuning Large Language Models with Sequential Instructions

This is the code to replicate the instruction tuning experiments in the paper [*Fine-tuning Large Language Models with Sequential Instructions*]. [[cite]](#citation)

For our implementation based on the Alpaca-LoRA and LAVIS repository, please visit [Alpaca-LoRA](https://github.com/tloen/alpaca-lora), and [LAVIS](https://github.com/salesforce/LAVIS/tree/main).

